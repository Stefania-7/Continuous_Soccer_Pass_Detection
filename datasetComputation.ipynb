{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset Creation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"data/full-game.csv\", names=['sid', 'ts', 'x', 'y', 'z', '|v|', '|a|', 'vx', 'vy', 'vz', 'ax', 'ay', 'az'])\n",
    "\n",
    "df_passList = pd.read_csv(\"data/passList.csv\", names=['ts', 'sid', 'tsRec', 'sidRec'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "df_randomList = pd.read_csv(\"data/randomList.csv\", names=['ts', 'sid']) # 1000\n",
    "df_randomList1 = pd.read_csv(\"data/randomList1.csv\", names=['ts', 'sid']) # 2000\n",
    "df_randomList2 = pd.read_csv(\"data/randomList2.csv\", names=['ts', 'sid']) # 4000\n",
    "df_randomList3 = pd.read_csv(\"data/randomList3.csv\", names=['ts', 'sid']) # 6000\n",
    "df_randomList4 = pd.read_csv(\"data/randomList4.csv\", names=['ts', 'sid']) # 8000\n",
    "df_randomList5 = pd.read_csv(\"data/randomList5.csv\", names=['ts', 'sid']) # 10000"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset 1000"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mean"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "mean_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['ts', 'sid', '|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        mean_dict = dataFilter.mean().to_dict()\n",
    "        mean_df = pd.concat([mean_df, pd.DataFrame(mean_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['ts', 'sid', '|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        mean_dict = dataFilter.mean().to_dict()\n",
    "        mean_df = pd.concat([mean_df, pd.DataFrame(mean_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "mean_df.rename(columns={'ts': 'ts', 'sid': 'sid', '|v|': '|v|_mean','|a|': '|a|_mean','vz': 'vz_mean','az': 'az_mean'}, inplace=True)\n",
    "mean_df.to_csv('data/mean_df.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Standard Deviation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "std_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        std_dict = dataFilter.std().to_dict()\n",
    "        std_df = pd.concat([std_df, pd.DataFrame(std_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        std_dict = dataFilter.std().to_dict()\n",
    "        std_df = pd.concat([std_df, pd.DataFrame(std_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "std_df.rename(columns={'|v|': '|v|_std', '|a|': '|a|_std', 'vz': 'vz_std', 'az': 'az_std'}, inplace=True)\n",
    "std_df.to_csv('data/std_df.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Minimum"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "min_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        min_dict = dataFilter.min().to_dict()\n",
    "        min_df = pd.concat([min_df, pd.DataFrame(min_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        min_dict = dataFilter.min().to_dict()\n",
    "        min_df = pd.concat([min_df, pd.DataFrame(min_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "min_df.rename(columns={'|v|': '|v|_min', '|a|': '|a|_min', 'vz': 'vz_min', 'az': 'az_min'}, inplace=True)\n",
    "min_df.to_csv('data/min_df.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Maximum"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "max_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        max_dict = dataFilter.max().to_dict()\n",
    "        max_df = pd.concat([max_df, pd.DataFrame(max_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        max_dict = dataFilter.max().to_dict()\n",
    "        max_df = pd.concat([max_df, pd.DataFrame(max_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "max_df.rename(columns={'|v|': '|v|_max', '|a|': '|a|_max', 'vz': 'vz_max', 'az': 'az_max'}, inplace=True)\n",
    "max_df.to_csv('data/max_df.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "mean_df = pd.read_csv(\"data/mean_df.csv\")\n",
    "std_df = pd.read_csv(\"data/std_df.csv\")\n",
    "min_df = pd.read_csv(\"data/min_df.csv\")\n",
    "max_df = pd.read_csv(\"data/max_df.csv\")\n",
    "label_df = pd.read_csv(\"data/labelList.csv\")\n",
    "\n",
    "dataset = pd.concat([mean_df, std_df, min_df, max_df, label_df], axis=1)\n",
    "dataset.to_csv('data/dataset.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ordered Dataset 1000"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Load dataset into a pandas DataFrame\n",
    "old_ds = pd.read_csv('data/dataset.csv')\n",
    "\n",
    "# Sort the DataFrame by 'timestamp'\n",
    "old_ds = old_ds.sort_values(by='ts')\n",
    "\n",
    "old_ds.to_csv('data/dataset1000.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset 1500"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mean"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "mean_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['ts', 'sid', '|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        mean_dict = dataFilter.mean().to_dict()\n",
    "        mean_df = pd.concat([mean_df, pd.DataFrame(mean_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList1.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['ts', 'sid', '|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        mean_dict = dataFilter.mean().to_dict()\n",
    "        mean_df = pd.concat([mean_df, pd.DataFrame(mean_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "mean_df.rename(columns={'ts': 'ts', 'sid': 'sid', '|v|': '|v|_mean','|a|': '|a|_mean','vz': 'vz_mean','az': 'az_mean'}, inplace=True)\n",
    "mean_df.to_csv('data/mean1_df.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Standard Deviation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "std_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        std_dict = dataFilter.std().to_dict()\n",
    "        std_df = pd.concat([std_df, pd.DataFrame(std_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList1.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        std_dict = dataFilter.std().to_dict()\n",
    "        std_df = pd.concat([std_df, pd.DataFrame(std_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "std_df.rename(columns={'|v|': '|v|_std', '|a|': '|a|_std', 'vz': 'vz_std', 'az': 'az_std'}, inplace=True)\n",
    "std_df.to_csv('data/std1_df.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Minimum"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "min_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        min_dict = dataFilter.min().to_dict()\n",
    "        min_df = pd.concat([min_df, pd.DataFrame(min_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList1.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        min_dict = dataFilter.min().to_dict()\n",
    "        min_df = pd.concat([min_df, pd.DataFrame(min_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "min_df.rename(columns={'|v|': '|v|_min', '|a|': '|a|_min', 'vz': 'vz_min', 'az': 'az_min'}, inplace=True)\n",
    "min_df.to_csv('data/min1_df.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Maximum"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "max_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        max_dict = dataFilter.max().to_dict()\n",
    "        max_df = pd.concat([max_df, pd.DataFrame(max_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList1.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        max_dict = dataFilter.max().to_dict()\n",
    "        max_df = pd.concat([max_df, pd.DataFrame(max_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "max_df.rename(columns={'|v|': '|v|_max', '|a|': '|a|_max', 'vz': 'vz_max', 'az': 'az_max'}, inplace=True)\n",
    "max_df.to_csv('data/max1_df.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "mean_df = pd.read_csv(\"data/mean1_df.csv\")\n",
    "std_df = pd.read_csv(\"data/std1_df.csv\")\n",
    "min_df = pd.read_csv(\"data/min1_df.csv\")\n",
    "max_df = pd.read_csv(\"data/max1_df.csv\")\n",
    "label_df = pd.read_csv(\"data/labelList1.csv\")\n",
    "\n",
    "dataset = pd.concat([mean_df, std_df, min_df, max_df, label_df], axis=1)\n",
    "dataset.to_csv('data/dataset1.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ordered Dataset 1500"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Load dataset into a pandas DataFrame\n",
    "old_ds = pd.read_csv('data/dataset1.csv')\n",
    "\n",
    "# Sort the DataFrame by 'timestamp'\n",
    "old_ds = old_ds.sort_values(by='ts')\n",
    "\n",
    "old_ds.to_csv('data/dataset1500.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset 2500"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mean"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "mean_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['ts', 'sid', '|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        mean_dict = dataFilter.mean().to_dict()\n",
    "        mean_df = pd.concat([mean_df, pd.DataFrame(mean_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList2.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['ts', 'sid', '|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        mean_dict = dataFilter.mean().to_dict()\n",
    "        mean_df = pd.concat([mean_df, pd.DataFrame(mean_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "mean_df.rename(columns={'ts': 'ts', 'sid': 'sid', '|v|': '|v|_mean','|a|': '|a|_mean','vz': 'vz_mean','az': 'az_mean'}, inplace=True)\n",
    "mean_df.to_csv('data/mean2_df.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Standard Deviation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "std_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        std_dict = dataFilter.std().to_dict()\n",
    "        std_df = pd.concat([std_df, pd.DataFrame(std_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList2.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        std_dict = dataFilter.std().to_dict()\n",
    "        std_df = pd.concat([std_df, pd.DataFrame(std_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "std_df.rename(columns={'|v|': '|v|_std', '|a|': '|a|_std', 'vz': 'vz_std', 'az': 'az_std'}, inplace=True)\n",
    "std_df.to_csv('data/std2_df.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Minimum"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "min_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        min_dict = dataFilter.min().to_dict()\n",
    "        min_df = pd.concat([min_df, pd.DataFrame(min_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList2.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        min_dict = dataFilter.min().to_dict()\n",
    "        min_df = pd.concat([min_df, pd.DataFrame(min_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "min_df.rename(columns={'|v|': '|v|_min', '|a|': '|a|_min', 'vz': 'vz_min', 'az': 'az_min'}, inplace=True)\n",
    "min_df.to_csv('data/min2_df.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Maximum"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "max_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        max_dict = dataFilter.max().to_dict()\n",
    "        max_df = pd.concat([max_df, pd.DataFrame(max_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList2.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        max_dict = dataFilter.max().to_dict()\n",
    "        max_df = pd.concat([max_df, pd.DataFrame(max_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "max_df.rename(columns={'|v|': '|v|_max', '|a|': '|a|_max', 'vz': 'vz_max', 'az': 'az_max'}, inplace=True)\n",
    "max_df.to_csv('data/max2_df.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "mean_df = pd.read_csv(\"data/mean2_df.csv\")\n",
    "std_df = pd.read_csv(\"data/std2_df.csv\")\n",
    "min_df = pd.read_csv(\"data/min2_df.csv\")\n",
    "max_df = pd.read_csv(\"data/max2_df.csv\")\n",
    "label_df = pd.read_csv(\"data/labelList2.csv\")\n",
    "\n",
    "dataset = pd.concat([mean_df, std_df, min_df, max_df, label_df], axis=1)\n",
    "dataset.to_csv('data/dataset2.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ordered Dataset 2500"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# Load dataset into a pandas DataFrame\n",
    "old_ds = pd.read_csv('data/dataset2.csv')\n",
    "\n",
    "# Sort the DataFrame by 'timestamp'\n",
    "old_ds = old_ds.sort_values(by='ts')\n",
    "\n",
    "old_ds.to_csv('data/dataset2500.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset 3500"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mean"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "mean_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['ts', 'sid', '|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        mean_dict = dataFilter.mean().to_dict()\n",
    "        mean_df = pd.concat([mean_df, pd.DataFrame(mean_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList3.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['ts', 'sid', '|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        mean_dict = dataFilter.mean().to_dict()\n",
    "        mean_df = pd.concat([mean_df, pd.DataFrame(mean_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "mean_df.rename(columns={'ts': 'ts', 'sid': 'sid', '|v|': '|v|_mean','|a|': '|a|_mean','vz': 'vz_mean','az': 'az_mean'}, inplace=True)\n",
    "mean_df.to_csv('data/mean3_df.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Standard Deviation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "std_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        std_dict = dataFilter.std().to_dict()\n",
    "        std_df = pd.concat([std_df, pd.DataFrame(std_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList3.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        std_dict = dataFilter.std().to_dict()\n",
    "        std_df = pd.concat([std_df, pd.DataFrame(std_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "std_df.rename(columns={'|v|': '|v|_std', '|a|': '|a|_std', 'vz': 'vz_std', 'az': 'az_std'}, inplace=True)\n",
    "std_df.to_csv('data/std3_df.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Minimum"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "min_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        min_dict = dataFilter.min().to_dict()\n",
    "        min_df = pd.concat([min_df, pd.DataFrame(min_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList3.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        min_dict = dataFilter.min().to_dict()\n",
    "        min_df = pd.concat([min_df, pd.DataFrame(min_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "min_df.rename(columns={'|v|': '|v|_min', '|a|': '|a|_min', 'vz': 'vz_min', 'az': 'az_min'}, inplace=True)\n",
    "min_df.to_csv('data/min3_df.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Maximum"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "max_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        max_dict = dataFilter.max().to_dict()\n",
    "        max_df = pd.concat([max_df, pd.DataFrame(max_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList3.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        max_dict = dataFilter.max().to_dict()\n",
    "        max_df = pd.concat([max_df, pd.DataFrame(max_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "max_df.rename(columns={'|v|': '|v|_max', '|a|': '|a|_max', 'vz': 'vz_max', 'az': 'az_max'}, inplace=True)\n",
    "max_df.to_csv('data/max3_df.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "mean_df = pd.read_csv(\"data/mean3_df.csv\")\n",
    "std_df = pd.read_csv(\"data/std3_df.csv\")\n",
    "min_df = pd.read_csv(\"data/min3_df.csv\")\n",
    "max_df = pd.read_csv(\"data/max3_df.csv\")\n",
    "label_df = pd.read_csv(\"data/labelList3.csv\")\n",
    "\n",
    "dataset = pd.concat([mean_df, std_df, min_df, max_df, label_df], axis=1)\n",
    "dataset.to_csv('data/dataset3.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ordered Dataset 3500"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# Load dataset into a pandas DataFrame\n",
    "old_ds = pd.read_csv('data/dataset3.csv')\n",
    "\n",
    "# Sort the DataFrame by 'timestamp'\n",
    "old_ds = old_ds.sort_values(by='ts')\n",
    "\n",
    "old_ds.to_csv('data/dataset3500.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset 4500"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mean"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "mean_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['ts', 'sid', '|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        mean_dict = dataFilter.mean().to_dict()\n",
    "        mean_df = pd.concat([mean_df, pd.DataFrame(mean_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList4.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['ts', 'sid', '|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        mean_dict = dataFilter.mean().to_dict()\n",
    "        mean_df = pd.concat([mean_df, pd.DataFrame(mean_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "mean_df.rename(columns={'ts': 'ts', 'sid': 'sid', '|v|': '|v|_mean','|a|': '|a|_mean','vz': 'vz_mean','az': 'az_mean'}, inplace=True)\n",
    "mean_df.to_csv('data/mean4_df.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Standard Deviation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "std_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        std_dict = dataFilter.std().to_dict()\n",
    "        std_df = pd.concat([std_df, pd.DataFrame(std_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList4.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        std_dict = dataFilter.std().to_dict()\n",
    "        std_df = pd.concat([std_df, pd.DataFrame(std_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "std_df.rename(columns={'|v|': '|v|_std', '|a|': '|a|_std', 'vz': 'vz_std', 'az': 'az_std'}, inplace=True)\n",
    "std_df.to_csv('data/std4_df.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Minimum"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "min_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        min_dict = dataFilter.min().to_dict()\n",
    "        min_df = pd.concat([min_df, pd.DataFrame(min_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList4.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        min_dict = dataFilter.min().to_dict()\n",
    "        min_df = pd.concat([min_df, pd.DataFrame(min_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "min_df.rename(columns={'|v|': '|v|_min', '|a|': '|a|_min', 'vz': 'vz_min', 'az': 'az_min'}, inplace=True)\n",
    "min_df.to_csv('data/min4_df.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Maximum"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "max_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        max_dict = dataFilter.max().to_dict()\n",
    "        max_df = pd.concat([max_df, pd.DataFrame(max_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList4.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        max_dict = dataFilter.max().to_dict()\n",
    "        max_df = pd.concat([max_df, pd.DataFrame(max_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "max_df.rename(columns={'|v|': '|v|_max', '|a|': '|a|_max', 'vz': 'vz_max', 'az': 'az_max'}, inplace=True)\n",
    "max_df.to_csv('data/max4_df.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "mean_df = pd.read_csv(\"data/mean4_df.csv\")\n",
    "std_df = pd.read_csv(\"data/std4_df.csv\")\n",
    "min_df = pd.read_csv(\"data/min4_df.csv\")\n",
    "max_df = pd.read_csv(\"data/max4_df.csv\")\n",
    "label_df = pd.read_csv(\"data/labelList4.csv\")\n",
    "\n",
    "dataset = pd.concat([mean_df, std_df, min_df, max_df, label_df], axis=1)\n",
    "dataset.to_csv('data/dataset4.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ordered Dataset 4500"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# Load dataset into a pandas DataFrame\n",
    "old_ds = pd.read_csv('data/dataset4.csv')\n",
    "\n",
    "# Sort the DataFrame by 'timestamp'\n",
    "old_ds = old_ds.sort_values(by='ts')\n",
    "\n",
    "old_ds.to_csv('data/dataset4500.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset 5500"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mean"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "mean_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['ts', 'sid', '|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        mean_dict = dataFilter.mean().to_dict()\n",
    "        mean_df = pd.concat([mean_df, pd.DataFrame(mean_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList5.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['ts', 'sid', '|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        mean_dict = dataFilter.mean().to_dict()\n",
    "        mean_df = pd.concat([mean_df, pd.DataFrame(mean_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "mean_df.rename(columns={'ts': 'ts', 'sid': 'sid', '|v|': '|v|_mean','|a|': '|a|_mean','vz': 'vz_mean','az': 'az_mean'}, inplace=True)\n",
    "mean_df.to_csv('data/mean5_df.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Standard Deviation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "std_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        std_dict = dataFilter.std().to_dict()\n",
    "        std_df = pd.concat([std_df, pd.DataFrame(std_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList5.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        std_dict = dataFilter.std().to_dict()\n",
    "        std_df = pd.concat([std_df, pd.DataFrame(std_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "std_df.rename(columns={'|v|': '|v|_std', '|a|': '|a|_std', 'vz': 'vz_std', 'az': 'az_std'}, inplace=True)\n",
    "std_df.to_csv('data/std5_df.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Minimum"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "min_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        min_dict = dataFilter.min().to_dict()\n",
    "        min_df = pd.concat([min_df, pd.DataFrame(min_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList5.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        min_dict = dataFilter.min().to_dict()\n",
    "        min_df = pd.concat([min_df, pd.DataFrame(min_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "min_df.rename(columns={'|v|': '|v|_min', '|a|': '|a|_min', 'vz': 'vz_min', 'az': 'az_min'}, inplace=True)\n",
    "min_df.to_csv('data/min5_df.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Maximum"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "max_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        max_dict = dataFilter.max().to_dict()\n",
    "        max_df = pd.concat([max_df, pd.DataFrame(max_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList5.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        max_dict = dataFilter.max().to_dict()\n",
    "        max_df = pd.concat([max_df, pd.DataFrame(max_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "max_df.rename(columns={'|v|': '|v|_max', '|a|': '|a|_max', 'vz': 'vz_max', 'az': 'az_max'}, inplace=True)\n",
    "max_df.to_csv('data/max5_df.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "mean_df = pd.read_csv(\"data/mean5_df.csv\")\n",
    "std_df = pd.read_csv(\"data/std5_df.csv\")\n",
    "min_df = pd.read_csv(\"data/min5_df.csv\")\n",
    "max_df = pd.read_csv(\"data/max5_df.csv\")\n",
    "label_df = pd.read_csv(\"data/labelList5.csv\")\n",
    "\n",
    "dataset = pd.concat([mean_df, std_df, min_df, max_df, label_df], axis=1)\n",
    "dataset.to_csv('data/dataset5.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ordered Dataset 5500"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# Load dataset into a pandas DataFrame\n",
    "old_ds = pd.read_csv('data/dataset5.csv')\n",
    "\n",
    "# Sort the DataFrame by 'timestamp'\n",
    "old_ds = old_ds.sort_values(by='ts')\n",
    "\n",
    "old_ds.to_csv('data/dataset5500.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
