{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Traditional Machine Learning Classification Dataset 1000"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, cohen_kappa_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train, Validation, Test"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Load the dataset into a Pandas DataFrame\n",
    "df = pd.read_csv('data/dataset1000.csv')\n",
    "\n",
    "# Convert the target variable to numerical values ('yes' replaced with 1 and 'no' replaced with 0)\n",
    "le = LabelEncoder()\n",
    "df['label_pass'] = le.fit_transform(df['label_pass'])\n",
    "\n",
    "# Split the DataFrame into data and target arrays\n",
    "data = df.iloc[:, 2:-1].values  # Select all columns except the first (if ts present) and last ones as the data array\n",
    "target = df.iloc[:, -1].values  # Select the last column as the target array"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (n_rows, n_cols) of X: (1000, 16), X_train: (700, 16), X_val: (200, 16), X_test: (100, 16)\n",
      "992280.52\n",
      "3492503.18\n",
      "4679892.01\n"
     ]
    }
   ],
   "source": [
    "# Define sizes of train, validation, and test sets\n",
    "size_train = 700\n",
    "size_val = 200\n",
    "size_test = 100\n",
    "\n",
    "# Calculate ratios based on the sizes\n",
    "total_size = size_train + size_val + size_test\n",
    "ratio_train = size_train / total_size\n",
    "ratio_val = size_val / total_size\n",
    "ratio_test = size_test / total_size\n",
    "\n",
    "# Produce test split\n",
    "X_remaining, X_test, y_remaining, y_test = train_test_split(data, target, test_size=ratio_test, shuffle=False, random_state=42)\n",
    "\n",
    "# Adjust val ratio, w.r.t. remaining dataset\n",
    "ratio_remaining = 1 - ratio_test\n",
    "ratio_val_adjusted = ratio_val / ratio_remaining\n",
    "\n",
    "# Produce train and val splits\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_remaining, y_remaining, test_size=ratio_val_adjusted, shuffle=False, random_state=42)\n",
    "\n",
    "print(f'Shape (n_rows, n_cols) of X: {data.shape}, 'f'X_train: {X_train.shape}, X_val: {X_val.shape}, X_test: {X_test.shape}')\n",
    "\n",
    "print(\"%.2f\" % X_train[0, 0])\n",
    "print(\"%.2f\" % X_val[0, 0])\n",
    "print(\"%.2f\" % X_test[0, 0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision Tree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracies averaged over 10 iterations w.r.t. Validation Set\n",
      "Accuracy: 0.69 ± 0.01\n",
      "Balanced Accuracy: 0.70 ± 0.01\n",
      "Geometric Mean: 0.69 ± 0.01\n",
      "Cohen's Kappa: 0.39 ± 0.01\n",
      "Model accuracies averaged over 10 iterations w.r.t. Test Set\n",
      "Accuracy: 0.72 ± 0.01\n",
      "Balanced Accuracy: 0.72 ± 0.01\n",
      "Geometric Mean: 0.72 ± 0.01\n",
      "Cohen's Kappa: 0.44 ± 0.01\n",
      "Precision: 0.73 ± 0.01\n",
      "Recall: 0.71 ± 0.01\n",
      "F1 Score: 0.72 ± 0.01\n"
     ]
    }
   ],
   "source": [
    "# Define the number of iterations for the loop\n",
    "n_iterations = 10\n",
    "\n",
    "# Define lists to store the accuracy metrics for each iteration\n",
    "accuracy_list_val = []\n",
    "balanced_accuracy_list_val = []\n",
    "geometric_mean_list_val = []\n",
    "cohen_kappa_list_val = []\n",
    "accuracy_list_test = []\n",
    "balanced_accuracy_list_test = []\n",
    "geometric_mean_list_test = []\n",
    "cohen_kappa_list_test = []\n",
    "precision_list_test = []\n",
    "recall_list_test = []\n",
    "f1_list_test = []\n",
    "\n",
    "# Loop over the random states\n",
    "for random_state in range(n_iterations):\n",
    "    model = DecisionTreeClassifier(random_state=random_state, criterion='gini')\n",
    "    model.fit(X=X_train, y=y_train)\n",
    "    y_predVal = model.predict(X=X_val)\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_predVal)\n",
    "    balanced_accuracy = balanced_accuracy_score(y_val, y_predVal)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val, y_predVal).ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    geometric_mean = math.sqrt(sensitivity * specificity)\n",
    "    cohen_kappa = cohen_kappa_score(y_val, y_predVal)\n",
    "\n",
    "    # Append the accuracy metrics to the lists\n",
    "    accuracy_list_val.append(accuracy)\n",
    "    balanced_accuracy_list_val.append(balanced_accuracy)\n",
    "    geometric_mean_list_val.append(geometric_mean)\n",
    "    cohen_kappa_list_val.append(cohen_kappa)\n",
    "\n",
    "    y_predTest = model.predict(X=X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_predTest)\n",
    "    balanced_accuracy = balanced_accuracy_score(y_test, y_predTest)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_predTest).ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    geometric_mean = math.sqrt(sensitivity * specificity)\n",
    "    cohen_kappa = cohen_kappa_score(y_test, y_predTest)\n",
    "    precision = precision_score(y_test, y_predTest)\n",
    "    recall = recall_score(y_test, y_predTest)\n",
    "    f1 = f1_score(y_test, y_predTest)\n",
    "\n",
    "    # Append the accuracy metrics to the lists\n",
    "    accuracy_list_test.append(accuracy)\n",
    "    balanced_accuracy_list_test.append(balanced_accuracy)\n",
    "    geometric_mean_list_test.append(geometric_mean)\n",
    "    cohen_kappa_list_test.append(cohen_kappa)\n",
    "    precision_list_test.append(precision)\n",
    "    recall_list_test.append(recall)\n",
    "    f1_list_test.append(f1)\n",
    "\n",
    "# Calculate the mean and standard deviation of the accuracy metrics\n",
    "accuracy_mean_val = np.mean(accuracy_list_val)\n",
    "accuracy_std_val = np.std(accuracy_list_val)\n",
    "balanced_accuracy_mean_val = np.mean(balanced_accuracy_list_val)\n",
    "balanced_accuracy_std_val = np.std(balanced_accuracy_list_val)\n",
    "geometric_mean_mean_val = np.mean(geometric_mean_list_val)\n",
    "geometric_mean_std_val = np.std(geometric_mean_list_val)\n",
    "cohen_kappa_mean_val = np.mean(cohen_kappa_list_val)\n",
    "cohen_kappa_std_val = np.std(cohen_kappa_list_val)\n",
    "accuracy_mean_test = np.mean(accuracy_list_test)\n",
    "accuracy_std_test = np.std(accuracy_list_test)\n",
    "balanced_accuracy_mean_test = np.mean(balanced_accuracy_list_test)\n",
    "balanced_accuracy_std_test = np.std(balanced_accuracy_list_test)\n",
    "geometric_mean_mean_test = np.mean(geometric_mean_list_test)\n",
    "geometric_mean_std_test = np.std(geometric_mean_list_test)\n",
    "cohen_kappa_mean_test = np.mean(cohen_kappa_list_test)\n",
    "cohen_kappa_std_test = np.std(cohen_kappa_list_test)\n",
    "precision_mean_test = np.mean(precision_list_test)\n",
    "precision_std_test = np.std(precision_list_test)\n",
    "recall_mean_test = np.mean(recall_list_test)\n",
    "recall_std_test = np.std(recall_list_test)\n",
    "f1_mean_test = np.mean(f1_list_test)\n",
    "f1_std_test = np.std(f1_list_test)\n",
    "\n",
    "# Print the mean and standard deviation of the accuracy metrics\n",
    "print(f\"Model accuracies averaged over {n_iterations} iterations w.r.t. Validation Set\")\n",
    "print(f\"Accuracy: {accuracy_mean_val:.2f} ± {accuracy_std_val:.2f}\")\n",
    "print(f\"Balanced Accuracy: {balanced_accuracy_mean_val:.2f} ± {balanced_accuracy_std_val:.2f}\")\n",
    "print(f\"Geometric Mean: {geometric_mean_mean_val:.2f} ± {geometric_mean_std_val:.2f}\")\n",
    "print(f\"Cohen's Kappa: {cohen_kappa_mean_val:.2f} ± {cohen_kappa_std_val:.2f}\")\n",
    "print(f\"Model accuracies averaged over {n_iterations} iterations w.r.t. Test Set\")\n",
    "print(f\"Accuracy: {accuracy_mean_test:.2f} ± {accuracy_std_test:.2f}\")\n",
    "print(f\"Balanced Accuracy: {balanced_accuracy_mean_test:.2f} ± {balanced_accuracy_std_test:.2f}\")\n",
    "print(f\"Geometric Mean: {geometric_mean_mean_test:.2f} ± {geometric_mean_std_test:.2f}\")\n",
    "print(f\"Cohen's Kappa: {cohen_kappa_mean_test:.2f} ± {cohen_kappa_std_test:.2f}\")\n",
    "print(f\"Precision: {precision_mean_test:.2f} ± {precision_std_test:.2f}\")\n",
    "print(f\"Recall: {recall_mean_test:.2f} ± {recall_std_test:.2f}\")\n",
    "print(f\"F1 Score: {f1_mean_test:.2f} ± {f1_std_test:.2f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bagging"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracies averaged over 10 iterations w.r.t. Validation Set\n",
      "Accuracy: 0.75 ± 0.02\n",
      "Balanced Accuracy: 0.75 ± 0.02\n",
      "Geometric Mean: 0.74 ± 0.02\n",
      "Cohen's Kappa: 0.49 ± 0.04\n",
      "Model accuracies averaged over 10 iterations w.r.t. Test Set\n",
      "Accuracy: 0.80 ± 0.02\n",
      "Balanced Accuracy: 0.80 ± 0.02\n",
      "Geometric Mean: 0.80 ± 0.02\n",
      "Cohen's Kappa: 0.61 ± 0.03\n",
      "Precision: 0.84 ± 0.02\n",
      "Recall: 0.76 ± 0.02\n",
      "F1 Score: 0.80 ± 0.02\n"
     ]
    }
   ],
   "source": [
    "# Define the number of iterations for the loop\n",
    "n_iterations = 10\n",
    "\n",
    "# Define lists to store the accuracy metrics for each iteration\n",
    "accuracy_list_val = []\n",
    "balanced_accuracy_list_val = []\n",
    "geometric_mean_list_val = []\n",
    "cohen_kappa_list_val = []\n",
    "accuracy_list_test = []\n",
    "balanced_accuracy_list_test = []\n",
    "geometric_mean_list_test = []\n",
    "cohen_kappa_list_test = []\n",
    "precision_list_test = []\n",
    "recall_list_test = []\n",
    "f1_list_test = []\n",
    "\n",
    "# Loop over the random states\n",
    "for random_state in range(n_iterations):\n",
    "    model = BaggingClassifier(DecisionTreeClassifier(random_state=42, criterion='gini'), n_estimators=10, random_state=random_state)\n",
    "    model.fit(X=X_train, y=y_train)\n",
    "    y_predVal = model.predict(X=X_val)\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_predVal)\n",
    "    balanced_accuracy = balanced_accuracy_score(y_val, y_predVal)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val, y_predVal).ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    geometric_mean = math.sqrt(sensitivity * specificity)\n",
    "    cohen_kappa = cohen_kappa_score(y_val, y_predVal)\n",
    "\n",
    "    # Append the accuracy metrics to the lists\n",
    "    accuracy_list_val.append(accuracy)\n",
    "    balanced_accuracy_list_val.append(balanced_accuracy)\n",
    "    geometric_mean_list_val.append(geometric_mean)\n",
    "    cohen_kappa_list_val.append(cohen_kappa)\n",
    "\n",
    "    y_predTest = model.predict(X=X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_predTest)\n",
    "    balanced_accuracy = balanced_accuracy_score(y_test, y_predTest)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_predTest).ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    geometric_mean = math.sqrt(sensitivity * specificity)\n",
    "    cohen_kappa = cohen_kappa_score(y_test, y_predTest)\n",
    "    precision = precision_score(y_test, y_predTest)\n",
    "    recall = recall_score(y_test, y_predTest)\n",
    "    f1 = f1_score(y_test, y_predTest)\n",
    "\n",
    "    # Append the accuracy metrics to the lists\n",
    "    accuracy_list_test.append(accuracy)\n",
    "    balanced_accuracy_list_test.append(balanced_accuracy)\n",
    "    geometric_mean_list_test.append(geometric_mean)\n",
    "    cohen_kappa_list_test.append(cohen_kappa)\n",
    "    precision_list_test.append(precision)\n",
    "    recall_list_test.append(recall)\n",
    "    f1_list_test.append(f1)\n",
    "\n",
    "# Calculate the mean and standard deviation of the accuracy metrics\n",
    "accuracy_mean_val = np.mean(accuracy_list_val)\n",
    "accuracy_std_val = np.std(accuracy_list_val)\n",
    "balanced_accuracy_mean_val = np.mean(balanced_accuracy_list_val)\n",
    "balanced_accuracy_std_val = np.std(balanced_accuracy_list_val)\n",
    "geometric_mean_mean_val = np.mean(geometric_mean_list_val)\n",
    "geometric_mean_std_val = np.std(geometric_mean_list_val)\n",
    "cohen_kappa_mean_val = np.mean(cohen_kappa_list_val)\n",
    "cohen_kappa_std_val = np.std(cohen_kappa_list_val)\n",
    "accuracy_mean_test = np.mean(accuracy_list_test)\n",
    "accuracy_std_test = np.std(accuracy_list_test)\n",
    "balanced_accuracy_mean_test = np.mean(balanced_accuracy_list_test)\n",
    "balanced_accuracy_std_test = np.std(balanced_accuracy_list_test)\n",
    "geometric_mean_mean_test = np.mean(geometric_mean_list_test)\n",
    "geometric_mean_std_test = np.std(geometric_mean_list_test)\n",
    "cohen_kappa_mean_test = np.mean(cohen_kappa_list_test)\n",
    "cohen_kappa_std_test = np.std(cohen_kappa_list_test)\n",
    "precision_mean_test = np.mean(precision_list_test)\n",
    "precision_std_test = np.std(precision_list_test)\n",
    "recall_mean_test = np.mean(recall_list_test)\n",
    "recall_std_test = np.std(recall_list_test)\n",
    "f1_mean_test = np.mean(f1_list_test)\n",
    "f1_std_test = np.std(f1_list_test)\n",
    "\n",
    "# Print the mean and standard deviation of the accuracy metrics\n",
    "print(f\"Model accuracies averaged over {n_iterations} iterations w.r.t. Validation Set\")\n",
    "print(f\"Accuracy: {accuracy_mean_val:.2f} ± {accuracy_std_val:.2f}\")\n",
    "print(f\"Balanced Accuracy: {balanced_accuracy_mean_val:.2f} ± {balanced_accuracy_std_val:.2f}\")\n",
    "print(f\"Geometric Mean: {geometric_mean_mean_val:.2f} ± {geometric_mean_std_val:.2f}\")\n",
    "print(f\"Cohen's Kappa: {cohen_kappa_mean_val:.2f} ± {cohen_kappa_std_val:.2f}\")\n",
    "print(f\"Model accuracies averaged over {n_iterations} iterations w.r.t. Test Set\")\n",
    "print(f\"Accuracy: {accuracy_mean_test:.2f} ± {accuracy_std_test:.2f}\")\n",
    "print(f\"Balanced Accuracy: {balanced_accuracy_mean_test:.2f} ± {balanced_accuracy_std_test:.2f}\")\n",
    "print(f\"Geometric Mean: {geometric_mean_mean_test:.2f} ± {geometric_mean_std_test:.2f}\")\n",
    "print(f\"Cohen's Kappa: {cohen_kappa_mean_test:.2f} ± {cohen_kappa_std_test:.2f}\")\n",
    "print(f\"Precision: {precision_mean_test:.2f} ± {precision_std_test:.2f}\")\n",
    "print(f\"Recall: {recall_mean_test:.2f} ± {recall_std_test:.2f}\")\n",
    "print(f\"F1 Score: {f1_mean_test:.2f} ± {f1_std_test:.2f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracies averaged over 10 iterations w.r.t. Validation Set\n",
      "Accuracy: 0.74 ± 0.02\n",
      "Balanced Accuracy: 0.74 ± 0.02\n",
      "Geometric Mean: 0.73 ± 0.02\n",
      "Cohen's Kappa: 0.47 ± 0.04\n",
      "Model accuracies averaged over 10 iterations w.r.t. Test Set\n",
      "Accuracy: 0.80 ± 0.02\n",
      "Balanced Accuracy: 0.80 ± 0.02\n",
      "Geometric Mean: 0.80 ± 0.02\n",
      "Cohen's Kappa: 0.59 ± 0.04\n",
      "Precision: 0.84 ± 0.03\n",
      "Recall: 0.75 ± 0.03\n",
      "F1 Score: 0.79 ± 0.02\n"
     ]
    }
   ],
   "source": [
    "# Define the number of iterations for the loop\n",
    "n_iterations = 10\n",
    "\n",
    "# Define lists to store the accuracy metrics for each iteration\n",
    "accuracy_list_val = []\n",
    "balanced_accuracy_list_val = []\n",
    "geometric_mean_list_val = []\n",
    "cohen_kappa_list_val = []\n",
    "accuracy_list_test = []\n",
    "balanced_accuracy_list_test = []\n",
    "geometric_mean_list_test = []\n",
    "cohen_kappa_list_test = []\n",
    "precision_list_test = []\n",
    "recall_list_test = []\n",
    "f1_list_test = []\n",
    "\n",
    "# Loop over the random states\n",
    "for random_state in range(n_iterations):\n",
    "    model = RandomForestClassifier(n_estimators=10, criterion='gini', random_state=random_state)\n",
    "    model.fit(X=X_train, y=y_train)\n",
    "    y_predVal = model.predict(X=X_val)\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_predVal)\n",
    "    balanced_accuracy = balanced_accuracy_score(y_val, y_predVal)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val, y_predVal).ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    geometric_mean = math.sqrt(sensitivity * specificity)\n",
    "    cohen_kappa = cohen_kappa_score(y_val, y_predVal)\n",
    "\n",
    "    # Append the accuracy metrics to the lists\n",
    "    accuracy_list_val.append(accuracy)\n",
    "    balanced_accuracy_list_val.append(balanced_accuracy)\n",
    "    geometric_mean_list_val.append(geometric_mean)\n",
    "    cohen_kappa_list_val.append(cohen_kappa)\n",
    "\n",
    "    y_predTest = model.predict(X=X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_predTest)\n",
    "    balanced_accuracy = balanced_accuracy_score(y_test, y_predTest)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_predTest).ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    geometric_mean = math.sqrt(sensitivity * specificity)\n",
    "    cohen_kappa = cohen_kappa_score(y_test, y_predTest)\n",
    "    precision = precision_score(y_test, y_predTest)\n",
    "    recall = recall_score(y_test, y_predTest)\n",
    "    f1 = f1_score(y_test, y_predTest)\n",
    "\n",
    "    # Append the accuracy metrics to the lists\n",
    "    accuracy_list_test.append(accuracy)\n",
    "    balanced_accuracy_list_test.append(balanced_accuracy)\n",
    "    geometric_mean_list_test.append(geometric_mean)\n",
    "    cohen_kappa_list_test.append(cohen_kappa)\n",
    "    precision_list_test.append(precision)\n",
    "    recall_list_test.append(recall)\n",
    "    f1_list_test.append(f1)\n",
    "\n",
    "# Calculate the mean and standard deviation of the accuracy metrics\n",
    "accuracy_mean_val = np.mean(accuracy_list_val)\n",
    "accuracy_std_val = np.std(accuracy_list_val)\n",
    "balanced_accuracy_mean_val = np.mean(balanced_accuracy_list_val)\n",
    "balanced_accuracy_std_val = np.std(balanced_accuracy_list_val)\n",
    "geometric_mean_mean_val = np.mean(geometric_mean_list_val)\n",
    "geometric_mean_std_val = np.std(geometric_mean_list_val)\n",
    "cohen_kappa_mean_val = np.mean(cohen_kappa_list_val)\n",
    "cohen_kappa_std_val = np.std(cohen_kappa_list_val)\n",
    "accuracy_mean_test = np.mean(accuracy_list_test)\n",
    "accuracy_std_test = np.std(accuracy_list_test)\n",
    "balanced_accuracy_mean_test = np.mean(balanced_accuracy_list_test)\n",
    "balanced_accuracy_std_test = np.std(balanced_accuracy_list_test)\n",
    "geometric_mean_mean_test = np.mean(geometric_mean_list_test)\n",
    "geometric_mean_std_test = np.std(geometric_mean_list_test)\n",
    "cohen_kappa_mean_test = np.mean(cohen_kappa_list_test)\n",
    "cohen_kappa_std_test = np.std(cohen_kappa_list_test)\n",
    "precision_mean_test = np.mean(precision_list_test)\n",
    "precision_std_test = np.std(precision_list_test)\n",
    "recall_mean_test = np.mean(recall_list_test)\n",
    "recall_std_test = np.std(recall_list_test)\n",
    "f1_mean_test = np.mean(f1_list_test)\n",
    "f1_std_test = np.std(f1_list_test)\n",
    "\n",
    "# Print the mean and standard deviation of the accuracy metrics\n",
    "print(f\"Model accuracies averaged over {n_iterations} iterations w.r.t. Validation Set\")\n",
    "print(f\"Accuracy: {accuracy_mean_val:.2f} ± {accuracy_std_val:.2f}\")\n",
    "print(f\"Balanced Accuracy: {balanced_accuracy_mean_val:.2f} ± {balanced_accuracy_std_val:.2f}\")\n",
    "print(f\"Geometric Mean: {geometric_mean_mean_val:.2f} ± {geometric_mean_std_val:.2f}\")\n",
    "print(f\"Cohen's Kappa: {cohen_kappa_mean_val:.2f} ± {cohen_kappa_std_val:.2f}\")\n",
    "print(f\"Model accuracies averaged over {n_iterations} iterations w.r.t. Test Set\")\n",
    "print(f\"Accuracy: {accuracy_mean_test:.2f} ± {accuracy_std_test:.2f}\")\n",
    "print(f\"Balanced Accuracy: {balanced_accuracy_mean_test:.2f} ± {balanced_accuracy_std_test:.2f}\")\n",
    "print(f\"Geometric Mean: {geometric_mean_mean_test:.2f} ± {geometric_mean_std_test:.2f}\")\n",
    "print(f\"Cohen's Kappa: {cohen_kappa_mean_test:.2f} ± {cohen_kappa_std_test:.2f}\")\n",
    "print(f\"Precision: {precision_mean_test:.2f} ± {precision_std_test:.2f}\")\n",
    "print(f\"Recall: {recall_mean_test:.2f} ± {recall_std_test:.2f}\")\n",
    "print(f\"F1 Score: {f1_mean_test:.2f} ± {f1_std_test:.2f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
