{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"data/full-game.csv\", names=['sid', 'ts', 'x', 'y', 'z', '|v|', '|a|', 'vx', 'vy', 'vz', 'ax', 'ay', 'az'])\n",
    "\n",
    "df_passList = pd.read_csv(\"data/passList.csv\", names=['ts', 'sid', 'tsRec', 'sidRec'])\n",
    "\n",
    "df_randomList = pd.read_csv(\"data/randomListFin.csv\", names=['ts', 'sid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df to compute imbalanced test sets\n",
    "\n",
    "df_addRL1 = pd.read_csv(\"data/addRL1.csv\", names=['ts', 'sid'])\n",
    "df_addRL2 = pd.read_csv(\"data/addRL2.csv\", names=['ts', 'sid'])\n",
    "df_addRL3 = pd.read_csv(\"data/addRL3.csv\", names=['ts', 'sid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Balanced Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Mean Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['ts', '|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        mean_dict = dataFilter.mean().to_dict()\n",
    "        mean_df = pd.concat([mean_df, pd.DataFrame(mean_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['ts', '|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        mean_dict = dataFilter.mean().to_dict()\n",
    "        mean_df = pd.concat([mean_df, pd.DataFrame(mean_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "mean_df.rename(columns={'ts': 'ts','|v|': '|v|_mean','|a|': '|a|_mean','vz': 'vz_mean','az': 'az_mean'}, inplace=True)\n",
    "mean_df.to_csv('data/meanFin_df.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Standard Deviation Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "std_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        std_dict = dataFilter.std().to_dict()\n",
    "        std_df = pd.concat([std_df, pd.DataFrame(std_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        std_dict = dataFilter.std().to_dict()\n",
    "        std_df = pd.concat([std_df, pd.DataFrame(std_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "std_df.rename(columns={'|v|': '|v|_std', '|a|': '|a|_std', 'vz': 'vz_std', 'az': 'az_std'}, inplace=True)\n",
    "std_df.to_csv('data/stdFin_df.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Minimum Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        min_dict = dataFilter.min().to_dict()\n",
    "        min_df = pd.concat([min_df, pd.DataFrame(min_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        min_dict = dataFilter.min().to_dict()\n",
    "        min_df = pd.concat([min_df, pd.DataFrame(min_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "min_df.rename(columns={'|v|': '|v|_min', '|a|': '|a|_min', 'vz': 'vz_min', 'az': 'az_min'}, inplace=True)\n",
    "min_df.to_csv('data/minFin_df.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Maximum Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        max_dict = dataFilter.max().to_dict()\n",
    "        max_df = pd.concat([max_df, pd.DataFrame(max_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        max_dict = dataFilter.max().to_dict()\n",
    "        max_df = pd.concat([max_df, pd.DataFrame(max_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "max_df.rename(columns={'|v|': '|v|_max', '|a|': '|a|_max', 'vz': 'vz_max', 'az': 'az_max'}, inplace=True)\n",
    "max_df.to_csv('data/maxFin_df.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Balanced Dataset with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_df = pd.read_csv(\"data/meanFin_df.csv\")\n",
    "std_df = pd.read_csv(\"data/stdFin_df.csv\")\n",
    "min_df = pd.read_csv(\"data/minFin_df.csv\")\n",
    "max_df = pd.read_csv(\"data/maxFin_df.csv\")\n",
    "label_df = pd.read_csv(\"data/labelListFin.csv\")\n",
    "\n",
    "dataset = pd.concat([mean_df, std_df, min_df, max_df, label_df], axis=1)\n",
    "dataset.to_csv('data/datasetFin.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Ordered Balanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load dataset into a pandas DataFrame\n",
    "old_ds = pd.read_csv('data/datasetFin.csv')\n",
    "\n",
    "# Sort the DataFrame by 'timestamp'\n",
    "old_ds = old_ds.sort_values(by='ts')\n",
    "\n",
    "old_ds.to_csv('data/new_dataset_fin.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Imbalanced Test Set 40-60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['ts', '|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        mean_dict = dataFilter.mean().to_dict()\n",
    "        mean_df = pd.concat([mean_df, pd.DataFrame(mean_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['ts', '|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        mean_dict = dataFilter.mean().to_dict()\n",
    "        mean_df = pd.concat([mean_df, pd.DataFrame(mean_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_addRL1.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['ts', '|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        mean_dict = dataFilter.mean().to_dict()\n",
    "        mean_df = pd.concat([mean_df, pd.DataFrame(mean_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "mean_df.rename(columns={'ts': 'ts','|v|': '|v|_mean','|a|': '|a|_mean','vz': 'vz_mean','az': 'az_mean'}, inplace=True)\n",
    "mean_df.to_csv('data/meanRL1_df.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "std_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        std_dict = dataFilter.std().to_dict()\n",
    "        std_df = pd.concat([std_df, pd.DataFrame(std_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        std_dict = dataFilter.std().to_dict()\n",
    "        std_df = pd.concat([std_df, pd.DataFrame(std_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_addRL1.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        std_dict = dataFilter.std().to_dict()\n",
    "        std_df = pd.concat([std_df, pd.DataFrame(std_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "std_df.rename(columns={'|v|': '|v|_std', '|a|': '|a|_std', 'vz': 'vz_std', 'az': 'az_std'}, inplace=True)\n",
    "std_df.to_csv('data/stdRL1_df.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        min_dict = dataFilter.min().to_dict()\n",
    "        min_df = pd.concat([min_df, pd.DataFrame(min_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        min_dict = dataFilter.min().to_dict()\n",
    "        min_df = pd.concat([min_df, pd.DataFrame(min_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_addRL1.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        min_dict = dataFilter.min().to_dict()\n",
    "        min_df = pd.concat([min_df, pd.DataFrame(min_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "min_df.rename(columns={'|v|': '|v|_min', '|a|': '|a|_min', 'vz': 'vz_min', 'az': 'az_min'}, inplace=True)\n",
    "min_df.to_csv('data/minRL1_df.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        max_dict = dataFilter.max().to_dict()\n",
    "        max_df = pd.concat([max_df, pd.DataFrame(max_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        max_dict = dataFilter.max().to_dict()\n",
    "        max_df = pd.concat([max_df, pd.DataFrame(max_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_addRL1.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        max_dict = dataFilter.max().to_dict()\n",
    "        max_df = pd.concat([max_df, pd.DataFrame(max_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "max_df.rename(columns={'|v|': '|v|_max', '|a|': '|a|_max', 'vz': 'vz_max', 'az': 'az_max'}, inplace=True)\n",
    "max_df.to_csv('data/maxRL1_df.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_df = pd.read_csv(\"data/meanRL1_df.csv\")\n",
    "std_df = pd.read_csv(\"data/stdRL1_df.csv\")\n",
    "min_df = pd.read_csv(\"data/minRL1_df.csv\")\n",
    "max_df = pd.read_csv(\"data/maxRL1_df.csv\")\n",
    "label_df = pd.read_csv(\"data/labelListRL1.csv\")\n",
    "\n",
    "dataset = pd.concat([mean_df, std_df, min_df, max_df, label_df], axis=1)\n",
    "dataset.to_csv('data/datasetRL1.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load dataset into a pandas DataFrame\n",
    "old_ds = pd.read_csv('data/datasetRL1.csv')\n",
    "\n",
    "# Sort the DataFrame by 'timestamp'\n",
    "old_ds = old_ds.sort_values(by='ts')\n",
    "\n",
    "old_ds.to_csv('data/new_dataset_4060.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Imbalanced Test Set 30-70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['ts', '|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        mean_dict = dataFilter.mean().to_dict()\n",
    "        mean_df = pd.concat([mean_df, pd.DataFrame(mean_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['ts', '|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        mean_dict = dataFilter.mean().to_dict()\n",
    "        mean_df = pd.concat([mean_df, pd.DataFrame(mean_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_addRL2.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['ts', '|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        mean_dict = dataFilter.mean().to_dict()\n",
    "        mean_df = pd.concat([mean_df, pd.DataFrame(mean_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "mean_df.rename(columns={'ts': 'ts','|v|': '|v|_mean','|a|': '|a|_mean','vz': 'vz_mean','az': 'az_mean'}, inplace=True)\n",
    "mean_df.to_csv('data/meanRL2_df.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "std_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        std_dict = dataFilter.std().to_dict()\n",
    "        std_df = pd.concat([std_df, pd.DataFrame(std_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        std_dict = dataFilter.std().to_dict()\n",
    "        std_df = pd.concat([std_df, pd.DataFrame(std_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_addRL2.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        std_dict = dataFilter.std().to_dict()\n",
    "        std_df = pd.concat([std_df, pd.DataFrame(std_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "std_df.rename(columns={'|v|': '|v|_std', '|a|': '|a|_std', 'vz': 'vz_std', 'az': 'az_std'}, inplace=True)\n",
    "std_df.to_csv('data/stdRL2_df.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        min_dict = dataFilter.min().to_dict()\n",
    "        min_df = pd.concat([min_df, pd.DataFrame(min_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        min_dict = dataFilter.min().to_dict()\n",
    "        min_df = pd.concat([min_df, pd.DataFrame(min_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_addRL2.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        min_dict = dataFilter.min().to_dict()\n",
    "        min_df = pd.concat([min_df, pd.DataFrame(min_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "min_df.rename(columns={'|v|': '|v|_min', '|a|': '|a|_min', 'vz': 'vz_min', 'az': 'az_min'}, inplace=True)\n",
    "min_df.to_csv('data/minRL2_df.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        max_dict = dataFilter.max().to_dict()\n",
    "        max_df = pd.concat([max_df, pd.DataFrame(max_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        max_dict = dataFilter.max().to_dict()\n",
    "        max_df = pd.concat([max_df, pd.DataFrame(max_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_addRL2.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        max_dict = dataFilter.max().to_dict()\n",
    "        max_df = pd.concat([max_df, pd.DataFrame(max_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "max_df.rename(columns={'|v|': '|v|_max', '|a|': '|a|_max', 'vz': 'vz_max', 'az': 'az_max'}, inplace=True)\n",
    "max_df.to_csv('data/maxRL2_df.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_df = pd.read_csv(\"data/meanRL2_df.csv\")\n",
    "std_df = pd.read_csv(\"data/stdRL2_df.csv\")\n",
    "min_df = pd.read_csv(\"data/minRL2_df.csv\")\n",
    "max_df = pd.read_csv(\"data/maxRL2_df.csv\")\n",
    "label_df = pd.read_csv(\"data/labelListRL2.csv\")\n",
    "\n",
    "dataset = pd.concat([mean_df, std_df, min_df, max_df, label_df], axis=1)\n",
    "dataset.to_csv('data/datasetRL2.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load dataset into a pandas DataFrame\n",
    "old_ds = pd.read_csv('data/datasetRL2.csv')\n",
    "\n",
    "# Sort the DataFrame by 'timestamp'\n",
    "old_ds = old_ds.sort_values(by='ts')\n",
    "\n",
    "old_ds.to_csv('data/new_dataset_3070.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Imbalanced Test Set 20-80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['ts', '|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        mean_dict = dataFilter.mean().to_dict()\n",
    "        mean_df = pd.concat([mean_df, pd.DataFrame(mean_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['ts', '|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        mean_dict = dataFilter.mean().to_dict()\n",
    "        mean_df = pd.concat([mean_df, pd.DataFrame(mean_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_addRL3.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['ts', '|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        mean_dict = dataFilter.mean().to_dict()\n",
    "        mean_df = pd.concat([mean_df, pd.DataFrame(mean_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "mean_df.rename(columns={'ts': 'ts','|v|': '|v|_mean','|a|': '|a|_mean','vz': 'vz_mean','az': 'az_mean'}, inplace=True)\n",
    "mean_df.to_csv('data/meanRL3_df.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "std_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        std_dict = dataFilter.std().to_dict()\n",
    "        std_df = pd.concat([std_df, pd.DataFrame(std_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        std_dict = dataFilter.std().to_dict()\n",
    "        std_df = pd.concat([std_df, pd.DataFrame(std_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_addRL3.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        std_dict = dataFilter.std().to_dict()\n",
    "        std_df = pd.concat([std_df, pd.DataFrame(std_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "std_df.rename(columns={'|v|': '|v|_std', '|a|': '|a|_std', 'vz': 'vz_std', 'az': 'az_std'}, inplace=True)\n",
    "std_df.to_csv('data/stdRL3_df.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        min_dict = dataFilter.min().to_dict()\n",
    "        min_df = pd.concat([min_df, pd.DataFrame(min_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        min_dict = dataFilter.min().to_dict()\n",
    "        min_df = pd.concat([min_df, pd.DataFrame(min_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_addRL3.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        min_dict = dataFilter.min().to_dict()\n",
    "        min_df = pd.concat([min_df, pd.DataFrame(min_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "min_df.rename(columns={'|v|': '|v|_min', '|a|': '|a|_min', 'vz': 'vz_min', 'az': 'az_min'}, inplace=True)\n",
    "min_df.to_csv('data/minRL3_df.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        max_dict = dataFilter.max().to_dict()\n",
    "        max_df = pd.concat([max_df, pd.DataFrame(max_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        max_dict = dataFilter.max().to_dict()\n",
    "        max_df = pd.concat([max_df, pd.DataFrame(max_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_addRL3.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        max_dict = dataFilter.max().to_dict()\n",
    "        max_df = pd.concat([max_df, pd.DataFrame(max_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "max_df.rename(columns={'|v|': '|v|_max', '|a|': '|a|_max', 'vz': 'vz_max', 'az': 'az_max'}, inplace=True)\n",
    "max_df.to_csv('data/maxRL3_df.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_df = pd.read_csv(\"data/meanRL3_df.csv\")\n",
    "std_df = pd.read_csv(\"data/stdRL3_df.csv\")\n",
    "min_df = pd.read_csv(\"data/minRL3_df.csv\")\n",
    "max_df = pd.read_csv(\"data/maxRL3_df.csv\")\n",
    "label_df = pd.read_csv(\"data/labelListRL3.csv\")\n",
    "\n",
    "dataset = pd.concat([mean_df, std_df, min_df, max_df, label_df], axis=1)\n",
    "dataset.to_csv('data/datasetRL3.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load dataset into a pandas DataFrame\n",
    "old_ds = pd.read_csv('data/datasetRL3.csv')\n",
    "\n",
    "# Sort the DataFrame by 'timestamp'\n",
    "old_ds = old_ds.sort_values(by='ts')\n",
    "\n",
    "old_ds.to_csv('data/new_dataset_2080.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Left-Right Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Sid Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sid_df = pd.DataFrame()\n",
    "\n",
    "for i, row in df_passList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['ts', '|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        sid_dict = {'sid': sid}  # Create a dictionary with only the 'sid' key and value\n",
    "        sid_df = pd.concat([sid_df, pd.DataFrame(sid_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "for i, row in df_randomList.iterrows():\n",
    "    sid = row['sid']\n",
    "    ts = row['ts']\n",
    "    tsDataFilter = data[(data['ts'] > ts - 0.3 * 1e12) & (data['ts'] <= ts + 0.3 * 1e12)]\n",
    "    sidDataFilter = tsDataFilter[(tsDataFilter['sid'] == sid)]\n",
    "    dataFilter = sidDataFilter[['ts', '|v|', '|a|', 'vz', 'az']]\n",
    "\n",
    "    if not dataFilter.empty:\n",
    "        sid_dict = {'sid': sid}  # Create a dictionary with only the 'sid' key and value\n",
    "        sid_df = pd.concat([sid_df, pd.DataFrame(sid_dict, index=[0])], ignore_index=True, verify_integrity=False, sort=False)\n",
    "\n",
    "sid_df.to_csv('data/sid_df.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Left-Right Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read the csv file\n",
    "sid_df = pd.read_csv('data/sid_df.csv')\n",
    "\n",
    "# Rename the column from 'sid' to 'foot'\n",
    "sid_df = sid_df.rename(columns={'sid': 'foot'})\n",
    "\n",
    "# Map the values of the 'foot' column to 'left' or 'right' based on whether the value is odd or even\n",
    "sid_df['foot'] = sid_df['foot'].apply(lambda x: 'right' if x % 2 == 0 else 'left')\n",
    "\n",
    "# Save the modified dataframe to a new CSV file\n",
    "sid_df.to_csv('data/foot_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the 'meanFin_df.csv' file into a dataframe\n",
    "meanFin_df = pd.read_csv('data/meanFin_df.csv')\n",
    "\n",
    "# Load the 'foot_df.csv' file into a dataframe\n",
    "foot_df = pd.read_csv('data/foot_df.csv')\n",
    "\n",
    "# Add the 'foot' column to the 'meanFin_df' dataframe as the second column\n",
    "meanFin_df.insert(1, 'foot', foot_df['foot'])\n",
    "\n",
    "# Save the modified dataframe to a new CSV file\n",
    "meanFin_df.to_csv('data/meanFoot_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Add Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_df = pd.read_csv(\"data/meanFoot_df.csv\")\n",
    "std_df = pd.read_csv(\"data/stdFin_df.csv\")\n",
    "min_df = pd.read_csv(\"data/minFin_df.csv\")\n",
    "max_df = pd.read_csv(\"data/maxFin_df.csv\")\n",
    "label_df = pd.read_csv(\"data/labelListFin.csv\")\n",
    "\n",
    "dataset = pd.concat([mean_df, std_df, min_df, max_df, label_df], axis=1)\n",
    "dataset.to_csv('data/datasetFoot.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Ordered Left-Right Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load dataset into a pandas DataFrame\n",
    "old_ds = pd.read_csv('data/datasetFoot.csv')\n",
    "\n",
    "# Sort the DataFrame by 'timestamp'\n",
    "old_ds = old_ds.sort_values(by='ts')\n",
    "\n",
    "old_ds.to_csv('data/new_dataset_foot.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Player Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the mapping of sid values to player numbers\n",
    "mapping = {62: 1, 61: 1, 64: 2, 63: 2, 66: 3, 65: 3, 68: 8, 67: 8, 38: 7, 69: 7,\n",
    "           40: 15, 71: 15, 74: 6, 73: 6, 44: 9, 75: 9, 14: 12, 13: 12, 16: 4, 47: 4,\n",
    "           88: 5, 49: 5, 52: 11, 19: 11, 54: 14, 53: 14, 24: 13, 23: 13, 58: 16, 57: 16,\n",
    "           28: 10, 59: 10}\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "sid_df = pd.read_csv('data/sid_df.csv')\n",
    "\n",
    "# Rename the column as 'player'\n",
    "sid_df = sid_df.rename(columns={'sid': 'player'})\n",
    "\n",
    "# Map the sid values to player numbers\n",
    "sid_df['player'] = sid_df['player'].map(mapping)\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "sid_df.to_csv('data/player_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the 'meanFin_df.csv' file into a dataframe\n",
    "meanFin_df = pd.read_csv('data/meanFin_df.csv')\n",
    "\n",
    "# Load the 'player_df.csv' file into a dataframe\n",
    "player_df = pd.read_csv('data/player_df.csv')\n",
    "\n",
    "# Add the 'player' column to the 'meanFin_df' dataframe as the second column\n",
    "meanFin_df.insert(1, 'player', player_df['player'])\n",
    "\n",
    "# Save the modified dataframe to a new CSV file\n",
    "meanFin_df.to_csv('data/meanPlayer_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Add Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_df = pd.read_csv(\"data/meanPlayer_df.csv\")\n",
    "std_df = pd.read_csv(\"data/stdFin_df.csv\")\n",
    "min_df = pd.read_csv(\"data/minFin_df.csv\")\n",
    "max_df = pd.read_csv(\"data/maxFin_df.csv\")\n",
    "label_df = pd.read_csv(\"data/labelListFin.csv\")\n",
    "\n",
    "dataset = pd.concat([mean_df, std_df, min_df, max_df, label_df], axis=1)\n",
    "dataset.to_csv('data/datasetPlayer.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Ordered Player Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load dataset into a pandas DataFrame\n",
    "old_ds = pd.read_csv('data/datasetPlayer.csv')\n",
    "\n",
    "# Sort the DataFrame by 'timestamp'\n",
    "old_ds = old_ds.sort_values(by='ts')\n",
    "\n",
    "old_ds.to_csv('data/new_dataset_player.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# PlayerFoot Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the data frames\n",
    "player_df = pd.read_csv('data/player_df.csv')\n",
    "foot_df = pd.read_csv('data/foot_df.csv')\n",
    "meanFin_df = pd.read_csv('data/meanFin_df.csv')\n",
    "\n",
    "# Add the player column to meanFin_df\n",
    "meanFin_df.insert(1, 'player', player_df['player'])\n",
    "\n",
    "# Add the foot column to meanFin_df\n",
    "meanFin_df.insert(2, 'foot', foot_df['foot'])\n",
    "\n",
    "# Save the updated data frame\n",
    "meanFin_df.to_csv('data/meanPlayerFoot_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Add Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_df = pd.read_csv(\"data/meanPlayerFoot_df.csv\")\n",
    "std_df = pd.read_csv(\"data/stdFin_df.csv\")\n",
    "min_df = pd.read_csv(\"data/minFin_df.csv\")\n",
    "max_df = pd.read_csv(\"data/maxFin_df.csv\")\n",
    "label_df = pd.read_csv(\"data/labelListFin.csv\")\n",
    "\n",
    "dataset = pd.concat([mean_df, std_df, min_df, max_df, label_df], axis=1)\n",
    "dataset.to_csv('data/datasetPlayerFoot.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Ordered PlayerFoot Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load dataset into a pandas DataFrame\n",
    "old_ds = pd.read_csv('data/datasetPlayerFoot.csv')\n",
    "\n",
    "# Sort the DataFrame by 'timestamp'\n",
    "old_ds = old_ds.sort_values(by='ts')\n",
    "\n",
    "old_ds.to_csv('data/new_dataset_player-foot.csv', index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
